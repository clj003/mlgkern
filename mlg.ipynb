{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a notebook containing an attempt to implement the MLG kernel\n",
    "#\n",
    "# Below is a link to the reference implementation by horace:\n",
    "# https://github.com/horacepan/MLGkernel\n",
    "#\n",
    "#\n",
    "# TODO:\n",
    "# 0. Write input parsing for feature nodes and test it\n",
    "#\n",
    "# 1. Construct graph laplacians somehow, also choose Laplacian inputs\n",
    "# 2. Test LG kernel implementation\n",
    "# \n",
    "# 3. Implement FLG kernel (Implement feature mapping matrices)\n",
    "# 4. Test FLG kernel\n",
    "# \n",
    "# 5. Implement generalized FLG kernel\n",
    "# 6. Test generalized FLG kernel\n",
    "#\n",
    "# 7. Implement MLG kernel (May need to find a way to use MLS kernel)\n",
    "# 8. Test generalized MLG kernel\n",
    "#\n",
    "# 9. Optimize calculations of MLG kernel\n",
    "#  a. Implement finding the orthonormal basis\n",
    "#  b. DP for calculation of recursion\n",
    "# 10. Test final version of generalizes MLG kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parsing paths\n",
    "adj_mat_path = \"/home/mastercljohnson/MLG_KERNEL/MLGkernel/data/MUTAG.txt\"\n",
    "feature_path = \"/home/mastercljohnson/MLG_KERNEL/MLGkernel/data/MUTAG_nodelabels.txt\"\n",
    "\n",
    "# Note: the adjacency matrix can be weighted and this code should work for the weighted case as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parsing\n",
    "\n",
    "# Given the paths of the adj matrix file and feature file,\n",
    "# Return both the adjacency matrices and feature vectors in a list??\n",
    "def parse_files(adj_mat_p, feat_p):\n",
    "    num_of_graphs = 0\n",
    "    size_of_graph = 0\n",
    "    \n",
    "    # open the paths to the adj matrices and features\n",
    "    adj_mat_f = open(adj_mat_p, 'r')\n",
    "    feature_f = open(feat_p, 'r')\n",
    "    \n",
    "    num_of_graphs = int(adj_mat_f.readline() )\n",
    "    \n",
    "    # Make sure the adj matrix and feature file are for the same data\n",
    "    if(num_of_graphs == int(feature_f.readline()) ):\n",
    "        print(\"Adj Matrix and feature file have same number of graphs: \", num_of_graphs)\n",
    "    else:\n",
    "        print(\"Something is wrong with the data, num of graphs do not match for both files\")\n",
    "        \n",
    "    adj_line = 1\n",
    "    feat_line = 1\n",
    "    \n",
    "    # Begin parsing the files for adjacency matrices and feature files\n",
    "    adj_matrix_list =[]\n",
    "    feature_vec_list =[]\n",
    "    \n",
    "    which_graph = 0\n",
    "    while (which_graph < num_of_graphs):\n",
    "        read = adj_mat_f.readline()\n",
    "        \n",
    "        num_of_vert = int( read ) # number of vertices in this graph\n",
    "        if not(num_of_vert == int(feature_f.readline()) ):\n",
    "            print(\"Uhh Ohh, something has gone wrong with the parsing: \", num_of_vert )\n",
    "        \n",
    "        adj_mat = [] # construct an array of arrays for adjacency matrix\n",
    "        feature_vec_vert = []\n",
    "        \n",
    "        for ind in range(num_of_vert):\n",
    "            column = adj_mat_f.readline()\n",
    "            da_real_column = np.array([int(x) for x in column.split()])\n",
    "            adj_mat.append(da_real_column)\n",
    "            \n",
    "            label = int( feature_f.readline() )\n",
    "            feature_vec_vert.append(label)\n",
    "        \n",
    "        # Convert type and append to giant list of adjacency matrices\n",
    "        adj_mat = np.array(adj_mat)\n",
    "        adj_matrix_list.append(adj_mat)\n",
    "        \n",
    "        feature_vec_vert = np.array(feature_vec_vert)\n",
    "        feature_vec_list.append(feature_vec_vert)\n",
    "        \n",
    "        # Increment graph number\n",
    "        which_graph +=1\n",
    "        \n",
    "    return adj_matrix_list, feature_vec_list\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj Matrix and feature file have same number of graphs:  188\n"
     ]
    }
   ],
   "source": [
    "# Test the Input Parsing\n",
    "a_mats, f_vecs =  parse_files(adj_mat_path,feature_path)\n",
    "# print(f_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Lagrangian constructed from Adjacency matrix A\n",
    "# Notice that a weighted adjacency matrix can be used for\n",
    "# constructing a weighted lagrangian\n",
    "def form_lap(A):\n",
    "    D = np.diag(np.sum( A , axis=0))\n",
    "    return D - A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Regularized Laplacian\n",
    "# Given Laplacian L, eta a small constant \"regularizer\", I the identity matrix\n",
    "def comp_reg_lap(L, eta):\n",
    "    I = np.eye(L.shape[0])\n",
    "    return L + eta*I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LG kernel (Laplacian Graph kernel)\n",
    "# Given regularized graph Laplacians L_1 and L_2 (of same size?), parameter gamma for normalization\n",
    "\n",
    "# Optimize with log computations later on\n",
    "\n",
    "\n",
    "# What is ^(-1),is it inverse?\n",
    "def lg_kernel(L_1, L_2, gamma):\n",
    "    # Construct identity matrices\n",
    "    I1 = np.eye(L_1.shape[0])\n",
    "    I2 = np.eye(L_2.shape[0])\n",
    "    \n",
    "    S_1 = np.linalg.inv(L_1) + gamma*I1\n",
    "    S_2 = np.linalg.inv(L_2) + gamma*I2\n",
    "    \n",
    "    average = np.linalg.inv(S_1)/2 + np.linalg.inv(S_2)/2 \n",
    "    numer = np.sqrt( abs( np.power(average, -1) ) ) # hopefully this is the 1/...\n",
    "    denom = np.power( abs(S_1), 1/4 ) * np.power(abs(S_2), 1/4)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a graph Laplacian \n",
    "gamm = 0.001\n",
    "L1 = form_lap(a_mats[0])\n",
    "L2 = form_lap(a_mats[1])\n",
    "reg_L1 = comp_reg_lap(L1,gamm)\n",
    "reg_L2 = comp_reg_lap(L2,gamm)\n",
    "# V1_feat =\n",
    "# V2_feat =\n",
    "\n",
    "# print(lg_kernel(reg_L1,reg_L1, gamm)) # has output\n",
    "# print(flg_kernel(reg_L1,reg_L1, gamm)) # needs checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLG kernel (Feature space Laplacian Graph kernel)\n",
    "# Given regularized graph Laplacians L_1 and L_2\n",
    "# feature mapping matrices U_1 and U_2\n",
    "# parameter gamma\n",
    "def flg_kernel(L_1, L_2, U_1, U_2, gamma):\n",
    "    # Construct the identity matrices\n",
    "    I1 = np.eye(L_1.shape[0])\n",
    "    I2 = np.eye(L_2.shape[0])\n",
    "    \n",
    "    S_1 = U_1*np.linalg.inv(L_1)*np.transpose(U_1) + gamma*I1\n",
    "    S_2 = U_2*np.linalg.inv(L_2)*np.transpose(U_2) + gamma*I2\n",
    "    \n",
    "    average = np.linalg.inv(S_1)/2 + np.linalg.inv(S_2)/2 \n",
    "    numer = np.sqrt( abs( np.power(average, -1) ) ) # hopefully this is the 1/...\n",
    "    # To check if the above is correct, compare kernel calculation with c++ impl\n",
    "    denom = np.power( abs(S_1), 1/4 ) * np.power(abs(S_2), 1/4)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of the Gram Matrix\n",
    "# Given a vertex set V_feat of features vertices with an inner product kernel of features, construct gram matrix \n",
    "def construct_gram(V_feat):\n",
    "    return V_feat * V_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized FLG kernel\n",
    "\n",
    "# Find way to construct feature matrices\n",
    "\n",
    "# Base kernel\n",
    "# Given local feature vectors v1_feat and v2_feat\n",
    "def base_kernel(v1_feat,v2_feat):\n",
    "    return v1_feat*v2_feat # dot product\n",
    "\n",
    "# Given above and orthonormal basis of W = span{phi(v1),...,phi(vn1), phi(v1'),...,phi(vn2')}\n",
    "def gen_flg_kernel(L_1, L_2, Q_1, Q_2 ,gamma, kern):\n",
    "    # TODO: Construct Projection S_1_bar, S_2_bar\n",
    "    S_1 = np.transpose(Q_1)*inv(L_1)*Q_1 + gamma*I\n",
    "    S_2 = np.transpose(Q_2)*inv(L_2)*Q_2 + gamma*I\n",
    "    \n",
    "    average = S_1_bar^(-1)/2 + S_2_bar^(-1)/2 \n",
    "    numer = sqrt( abs( average^(-1) ) )\n",
    "    denom = abs(S_1_bar)^(1/4) * abs(S_2_bar)^(1/4)\n",
    "    return numer/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of an orthonormal basis for the flg kernels\n",
    "# Given joint Gram matrix K\n",
    "def construct_Q(K):\n",
    "    eigvals, r_eigvecs = np.linalg.eig(K) # compute eigenvalues and eigenvectors of K\n",
    "    # Construct Q matrix for projections\n",
    "    n = len(eigvals)\n",
    "    Q = np.zeros((n,n))\n",
    "    for j in (0,len(eigvals)):\n",
    "        Q[:,j] = sqrt(eigvals[j])*r_eigvecs[:,j] # construct Q\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neighborhoods which are nested within each layer\n",
    "# IE. below the distance is how many vertices away the current vertex is (DFS)\n",
    "def dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample vertices from a vertex set for low rank approximation of gram matrix K\n",
    "# Given a vertex set V, and number of vertices to be sampled m\n",
    "def sample_vset(V, m):\n",
    "    return NotImplemented # some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLG kernel (Multiscale Laplacian Graph Kernel)\n",
    "\n",
    "# Define a recursive base kernel\n",
    "# Given a nested sequence of l nbhds and vertices v1,v2 \n",
    "def rec_kern(v1,v2, l):\n",
    "    # G_l(v1), G_l(v2)\n",
    "    if (l == 1):\n",
    "        return gen_flg_kernel(G_l_v1, G_2_v2, G_Q_1, G_Q_2, gamma, base_kernel)\n",
    "    return gen_flg_kernel(G_l_v1, G_2_v2, G_Q_1, G_Q_2, gamma, rec_kern(l=l-1))\n",
    "\n",
    "def mlg_kernel(L_1, L_2, Q_1, Q_2, ortho_basis ,gamma, rec_kern):\n",
    "    return gen_flg_kernel(L_1, L_2, Q_1, Q_2, ortho_basis ,gamma, rec_kern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
